<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Amazon RDS | Jason A. French]]></title>
  <link href="http://frenchja.github.com/blog/categories/amazon-rds/atom.xml" rel="self"/>
  <link href="http://frenchja.github.com/"/>
  <updated>2014-07-14T18:38:03-07:00</updated>
  <id>http://frenchja.github.com/</id>
  <author>
    <name><![CDATA[Jason A. French]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using R with MySQL Databases]]></title>
    <link href="http://frenchja.github.com/blog/2014/07/03/using-r-with-mysql-databases/"/>
    <updated>2014-07-03T10:58:00-07:00</updated>
    <id>http://frenchja.github.com/blog/2014/07/03/using-r-with-mysql-databases</id>
    <content type="html"><![CDATA[<h2>Overview</h2>

<p>When I began using R, like most researchers I kept all my data in some combination
of R's native <a href="http://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html">data.frame</a>
format or a <a href="http://en.wikipedia.org/wiki/Comma-separated_values">CSV</a> file that my analysis would continually read.
However, as I began to analyze big datasets at the <a href="https://sapa-project.org">SAPA Project</a>
and at <a href="http://insightdatascience.com/">Insight</a>,
I realized that there is a lot of value to instead keeping your data in a MySQL database
and streaming it into R when necessary.
This post will briefly outline a few advantages of using a database to store data and run through a
basic example of using R to transfer data to MySQL.</p>

<!-- more -->


<h3>Memory Efficiency</h3>

<p>Relational databases, such as MySQL, organize data into <em>tables</em> (like a spreadsheet)
and can link values in tables to each other.  Generally speaking, they are better at handling large datasets and are more efficient
at storing and accessing data than CSVs due to compression and indexing.
The data stay in the MySQL database until accessed via a query, which is
different than how R approaches data.frames and CSVs.
When accessing data stored in a data.frame or CSV file in R, the data must all fit <em>in memory</em>.
However, this becomes a problem if when using a large dataset or if you're cursed with an older computer with &lt;= 4GB of RAM.
In these cases, every time you load your dataset or do a memory-intensive operation (e.g., polychoric correlations)
your computer will slow to a painful crawl as your hard drives grind while your operating system
switches to using <a href="http://en.wikipedia.org/wiki/Virtual_memory">virtual memory</a> or swap space, rather than RAM.
You could get around this by using random sampling to create a smaller subset (or multiple subsets
if you want to bootstrap), but you can also use this technique on a SQL database. The advantage is that SQL databases
only load the data you're working with into your local machine's RAM when you SELECT the data you need - leaving plenty of
memory for the actual analysis.</p>

<h3>Safety and Security</h3>

<p>Two additional reasons I prefer SQL databases are safety and security. Services such as
Amazon's RDS (i.e., Relational Database Service) offer frequent backups and easy replication
across instances. If the local machine dies, the data are safe and uncorrupted. If I were storing
data in an .Rdata file, I'd have to rely on my OS (e.g., Time Machine) or a cloud-based storage solution
(e.g., Dropbox or CrashPlan) to backup my data. Worse, if I were storing my data in an Excel database and Excel
crashed, I may risk losing years of progress.</p>

<p>Using MySQL, I can give a collaborator access
to only needed portions of the data by locking down their SQL user to certain tables
and operations. By limiting access, we limit risk of corruption and overwriting years of progress.</p>

<h3>Scalable as the need grows</h3>

<p>Last, I find databases such as MySQL to be more scalable due to cloud computing. In the case of using Amazon's RDS,
you can buy as much storage or bandwidth as you need to complete your analysis, dissertation,
or build your web app. If I need multiple nodes or machines to analyze the data, I don't need to keep a copy of
the data on each machine.  I simply pass the SQL authentication parameters to each machine and the
data is accessed from a central location.</p>

<p>So let's begin by setting up a <a href="http://aws.amazon.com/rds/free/">Free-Tier RDS service</a> on Amazon and then move some
data from R to the RDS database.</p>

<h2>Setting up an RDS Instance</h2>

<p>Amazon currently offers a Free Tier for their RDS storage.  It offers:</p>

<ul>
<li>Enough hours to run a DB Instance continuously each month,</li>
<li>20 GB of database storage,</li>
<li>10 million I/O operations, and</li>
<li>automated database backups.</li>
</ul>


<p>To setup an RDS instance:</p>

<ol>
<li>Sign into the AWS Management Console.</li>
<li>Select 'RDS' under the 'Database' group.</li>
<li>Click 'Launch DB Instance'.</li>
<li>Select 'MySQL' for the database engine.</li>
<li>Select 'No' when asked if you intend to use the database for production purposes. Accidentally selecting 'Yes' could result in hefty fees.</li>
<li>For 'Instance Class', select 'db.t1.micro', 'No' for 'Multi-AZ Deployment', and 20 GB for 'Allocated Storage'.</li>
<li>Click 'Next' and launch your RDS instance.</li>
</ol>


<p>At this point, you should have a blank RDS database with a master username and password combination. Be sure to test that you can connect - I suggest using <a href="http://www.sequelpro.com/">Sequel Pro</a>. <em>If you can't connect,
you may need to open up port 3306 in your EC2 Security Group</em>.</p>

<p>Click on your new RDS Instance to get the hostname to connect to and note the database name:</p>

<p><img class="center" src="/images/rds1.png"></p>

<p>Fire up Sequel Pro and test out your new database.  If you want to connect using SSL, you'll need the SSH key you generated when
you first created your EC2 instance (not covered here).</p>

<p><img class="center" src="/images/rds2.png"></p>

<h2>Installing the RMySQL package</h2>

<p>Previously, I found installing <a href="http://cran.r-project.org/web/packages/RMySQL/index.html">RMySQL</a> to be very difficult when I was using MacPorts.  However,
having switched to <a href="http://brew.sh/">Homebrew</a> on my new machine, RMySQL found all the MySQL headers and libraries as
<a href="http://brew.sh/">Homebrew</a> uses the <code>/usr/local</code> directory to store your software, which is already in your shell $PATH.</p>

<p>Before compiling RMySQL, first compile MySQL using Homebrew:</p>

<p>```bash Installing MySQL using Homebrew</p>

<h1>If you haven't already, install Homebrew:</h1>

<h1>ruby -e "$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)"</h1>

<h1>Install MySQL</h1>

<p>brew install mysql
```</p>

<p>```
==> Downloading https://downloads.sf.net/project/machomebrew/Bottles/mysql-5.6.1
Already downloaded: /Library/Caches/Homebrew/mysql-5.6.19.mavericks.bottle.tar.gz
==> Pouring mysql-5.6.19.mavericks.bottle.tar.gz
==> Caveats
A "/etc/my.cnf" from another install may interfere with a Homebrew-built
server starting up correctly.</p>

<p>To connect:</p>

<pre><code>mysql -uroot
</code></pre>

<p>To have launchd start mysql at login:</p>

<pre><code>ln -sfv /usr/local/opt/mysql/*.plist ~/Library/LaunchAgents
</code></pre>

<p>Then to load mysql now:</p>

<pre><code>launchctl load ~/Library/LaunchAgents/homebrew.mxcl.mysql.plist
</code></pre>

<p>Or, if you don't want/need launchctl, you can just run:</p>

<pre><code>mysql.server start
</code></pre>

<p>==> Summary
üç∫  /usr/local/Cellar/mysql/5.6.19: 9536 files, 338M</p>

<p>```</p>

<p>Next, compile RMySQL from source:</p>

<p><code>r Compiling RMySQL
install.packages('RMySQL', type = 'source')
</code></p>

<p>```
trying URL 'http://cran.rstudio.com/src/contrib/RMySQL_0.9-3.tar.gz'
Content type 'application/x-gzip' length 165363 bytes (161 Kb)</p>

<h1>opened URL</h1>

<p>downloaded 161 Kb</p>

<ul>
<li>installing <em>source</em> package ‚ÄòRMySQL‚Äô ...
<strong> package ‚ÄòRMySQL‚Äô successfully unpacked and MD5 sums checked
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking for compress in -lz... yes
checking for getopt_long in -lc... yes
checking for mysql_init in -lmysqlclient... yes
checking for egrep... grep -E
checking for ANSI C header files...
rm: conftest.dSYM: is a directory
rm: conftest.dSYM: is a directory
yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking mysql.h usability... no
checking mysql.h presence... no
checking for mysql.h... no
checking /usr/local/include/mysql/mysql.h usability... yes
checking /usr/local/include/mysql/mysql.h presence... yes
checking for /usr/local/include/mysql/mysql.h... yes
configure: creating ./config.status
config.status: creating src/Makevars
</strong> libs
clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/usr/local/include/mysql -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include    -fPIC  -Wall -mtune=core2 -g -O2  -c RS-DBI.c -o RS-DBI.o
clang -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I/usr/local/include/mysql -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include    -fPIC  -Wall -mtune=core2 -g -O2  -c RS-MySQL.c -o RS-MySQL.o
clang -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o RMySQL.so RS-DBI.o RS-MySQL.o -lmysqlclient -lz -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation
installing to /Library/Frameworks/R.framework/Versions/3.1/Resources/library/RMySQL/libs
<strong> R
</strong> inst
<strong> preparing package for lazy loading
Creating a generic function for ‚Äòformat‚Äô from package ‚Äòbase‚Äô in package ‚ÄòRMySQL‚Äô
Creating a generic function for ‚Äòprint‚Äô from package ‚Äòbase‚Äô in package ‚ÄòRMySQL‚Äô
</strong> help
<strong>* installing help indices
</strong> building package indices
** testing if installed package can be loaded</li>
<li>DONE (RMySQL)
```</li>
</ul>


<h2>Transferring Existing Data to/from MySQL</h2>

<p>Having a database is useless unless we can easily convert our existing data.frames
into MySQL tables.  Let's try this using the <code>Thurstone</code> dataset from the Revelle's <a href="http://cran.r-project.org/web/packages/psych/index.html"><code>psych</code></a> package:</p>

<p>```r Moving Thurstone to RDS
library(RMySQL)
library(psych)
con &lt;- dbConnect(MySQL(),</p>

<pre><code>user = 'RDSUser',
password = 'YourPass',
host = 'RDS Host',
dbname='YourDB')
</code></pre>

<p>dbWriteTable(conn = con, name = 'Test', value = as.data.frame(Thurstone))
```</p>

<p>There! Now we have transferred our data.frame to our SQL database.</p>

<p><img class="center" src="/images/rds3.png"></p>

<p>Similarly, if you want to read data <em>from</em> MySQL to R, we can use the <code>dbReadTable()</code> function,
which returns a data.frame object. You can keep your data in MySQL and stream portions into R for specific analyses.
Since <code>dbReadTable</code> outputs a data.frame, we can use this command in place of a data.frame.</p>

<p>Let's run an <code>omega()</code> factor analysis on the Thurstone table:</p>

<p><code>r Thurstone Omega
omega(dbReadTable(conn = con,name = 'Test'), title = "9 variables from Thurstone")
</code></p>

<p>```
Loading required package: MASS
Loading required package: GPArotation
Loading required package: parallel
9 variables from Thurstone
Call: omega(m = dbReadTable(conn = con, name = "Test"), title = "9 variables from Thurstone")
Alpha:                 0.89
G.6:                   0.91
Omega Hierarchical:    0.74
Omega H asymptotic:    0.79
Omega Total            0.93</p>

<p>Schmid Leiman Factor loadings greater than  0.2</p>

<pre><code>               g   F1*   F2*   F3*   h2   u2   p2
</code></pre>

<p>Sentences       0.71  0.57             0.82 0.18 0.61
Vocabulary      0.73  0.55             0.84 0.16 0.63
Sent_Completion 0.68  0.52             0.73 0.27 0.63
First_Letters   0.65        0.56       0.73 0.27 0.57
X4_Letter_Words 0.62        0.49       0.63 0.37 0.61
Suffixes        0.56        0.41       0.50 0.50 0.63
Letter_Series   0.59              0.61 0.72 0.28 0.48
Pedigrees       0.58  0.23        0.34 0.50 0.50 0.66
Letter_Group    0.54              0.46 0.53 0.47 0.56</p>

<p>With eigenvalues of:
   g  F1<em>  F2</em>  F3*
3.58 0.96 0.74 0.71</p>

<p>general/max  3.71   max/min =   1.35
mean percent general =  0.6    with sd =  0.05 and cv of  0.09
Explained Common Variance of the general factor =  0.6</p>

<p>The degrees of freedom are 12  and the fit is  0.01</p>

<p>The root mean square of the residuals is  0.01
The df corrected root mean square of the residuals is  0.01</p>

<p>Compare this with the adequacy of just a general factor and no group factors
The degrees of freedom for just the general factor are 27  and the fit is  1.48</p>

<p>The root mean square of the residuals is  0.14
The df corrected root mean square of the residuals is  0.16</p>

<p>Measures of factor score adequacy</p>

<pre><code>                                             g  F1*  F2*  F3*
</code></pre>

<p>Correlation of scores with factors            0.86 0.73 0.72 0.75
Multiple R square of scores with factors      0.74 0.54 0.52 0.56
Minimum correlation of factor score estimates 0.49 0.08 0.03 0.11</p>

<p> Total, General and Subset omega for each subset</p>

<pre><code>                                             g  F1*  F2*  F3*
</code></pre>

<p>Omega total for total scores and subscales    0.93 0.92 0.83 0.79
Omega general for total scores and subscales  0.74 0.58 0.50 0.47
Omega group for total scores and subscales    0.16 0.35 0.32 0.32
```</p>

<p><img class="center" src="/images/rds4.png"></p>

<p>In other analyses, you may only need a fraction of the MySQL table.  In these cases, we'd want to use the <code>dbGetQuery()</code> command and issue a MySQL statement to SELECT and aggregate the information.  Let's get a vector of Sentences correlations that are greater than 0.5:</p>

<p><code>r
dbGetQuery(conn = con, statement = "SELECT Sentences FROM Test WHERE Sentences &gt; 0.5;")
</code></p>

<p><code>
  Sentences
1     1.000
2     0.828
3     0.776
4     0.541
</code></p>

<h3>Safely storing credentials</h3>

<p>It's important to note that in the above example, although I passed the <code>user</code> and <code>password</code>
parameters within my <code>dbConnect()</code> function, you would <strong>never</strong> want to do this in production code that
you were sharing.  It's far better to store the credentials a text file where <code>dbConnect(MySQL())</code> will look when you don't pass any credentials:</p>

<p><code>bash ~/.my.cnf
user = youruser
password = yourpassword
host = yourhouse
dbname = yourdb
</code></p>

<h2>Useful Packages for Fast DB Operations</h2>

<p>Ideally, we want to have one set of analysis code that is agnostic to <em>how</em>
the data are stored.  I suggest looking into <a href="http://had.co.nz/">Hadley Wickham's</a> new <a href="http://blog.rstudio.org/2014/01/17/introducing-dplyr/"><code>dplyr</code></a> package
(<a href="https://github.com/hadley/dplyr">Github</a>). <code>dplyr</code> is able to filter, sort, group, and summarize data
quickly whether it is stored in a data.frame, data.table, or database. Database operations may not always be as
fast as a data.table operation, but again, the advantage is that you don't need to feed all of your data into memory.</p>

<p>Hadley provides a few vignettes for getting getting started with <code>dplyr</code>:</p>

<p><code>r
vignette("introduction", package = "dplyr")
vignette("databases", package = "dplyr")
</code></p>
]]></content>
  </entry>
  
</feed>
